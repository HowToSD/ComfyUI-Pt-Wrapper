# Ptf ReLU
The ReLU activation function.

This class provides a callable that applies the ReLU activation function 
from `torch.nn.functional`.

## Output
| Data type |
|---|
| Ptcallable |

<HR>
Category: PyTorch wrapper - Callable

ComfyUI Pt Wrapper Node Reference. Â© 2025 Hide Inada (HowToSD.com). All rights reserved.
